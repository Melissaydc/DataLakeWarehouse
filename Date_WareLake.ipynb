{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7s4EvAC/RWvleoh+wXU9X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Melissaydc/Data_Lake-Warehouse/blob/main/Date_WareLake.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxDzgVOg6uzd",
        "outputId": "7084b276-9b6d-4fc6-a2f1-210f6bcdf4fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Conteúdo do data_warehouse.csv\n",
            "           data  produto_id  quantidade  valor_total         nome    categoria\n",
            "0    2024-04-12         293         351         6616  Produto 293       Roupas\n",
            "1    2024-04-27         293         451         5317  Produto 293       Roupas\n",
            "2    2024-04-13         293         308         7405  Produto 293       Roupas\n",
            "3    2024-04-17         293         411         2087  Produto 293       Roupas\n",
            "4    2024-04-28         293         443         1181  Produto 293       Roupas\n",
            "..          ...         ...         ...          ...          ...          ...\n",
            "995  2024-04-14         403         283         2706  Produto 403       Roupas\n",
            "996  2024-04-22         343         411         2924  Produto 343  Eletrônicos\n",
            "997  2024-04-12          30         156         8871   Produto 30    Alimentos\n",
            "998  2024-04-05         517         114         2295  Produto 517       Roupas\n",
            "999  2024-04-24         421         377         5949  Produto 421    Alimentos\n",
            "\n",
            "[1000 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Define o tamanho limite de 600 para a Categ\n",
        "num_produtos = 600\n",
        "produtos = {\n",
        "    \"produto_id\": range(1, num_produtos + 1),\n",
        "    \"nome\": [f\"Produto {i}\" for i in range(1, num_produtos + 1)],\n",
        "    \"categoria\": np.random.choice([\"Eletrônicos\", \"Roupas\", \"Alimentos\"], num_produtos),\n",
        "}\n",
        "\n",
        "# Coloca os produtos dentro de um data frame\n",
        "df_produtos = pd.DataFrame(produtos)\n",
        "\n",
        "# Cria 1000 vendas\n",
        "num_vendas = 1000  #\n",
        "data_vendas = {\n",
        "    \"data\": np.random.choice(pd.date_range(\"2024-04-01\", periods=30), num_vendas),  #\n",
        "    \"produto_id\": np.random.randint(1, num_produtos + 1, num_vendas),\n",
        "    \"quantidade\": np.random.randint(50, 500, num_vendas),  #\n",
        "    \"valor_total\": np.random.randint(1000, 10000, num_vendas),  #\n",
        "}\n",
        "\n",
        "# Coloca as vendas dentro de um Data Frame\n",
        "df_vendas = pd.DataFrame(data_vendas)\n",
        "\n",
        "# Salva as Vendas e os Produtos dentro de arquivos CSV\n",
        "df_vendas.to_csv(\"vendas.csv\", index=False)\n",
        "df_produtos.to_csv(\"produtos.csv\", index=False)\n",
        "\n",
        "# Coloca as informações dos arquivos dentro das variaveis correspondentes\n",
        "df_vendas = pd.read_csv(\"vendas.csv\")\n",
        "df_produtos = pd.read_csv(\"produtos.csv\")\n",
        "\n",
        "# Junta as vendas e os produtos\n",
        "df_merge = pd.merge(df_vendas, df_produtos, on=\"produto_id\", how=\"inner\")\n",
        "\n",
        "# Cria um arquivo CSV para armazenar as informações que foram agrupadas\n",
        "df_merge.to_csv(\"data_warehouse.csv\", index=False)\n",
        "\n",
        "# Salva em uma variável para poder fazer a leitura do warehouse\n",
        "df_warehouse = pd.read_csv(\"data_warehouse.csv\")\n",
        "print(\"Conteúdo do data_warehouse.csv\")\n",
        "print(df_warehouse)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Cria uma pasta para guardar os arquivos\n",
        "if not os.path.exists('data_lake'):\n",
        "    os.makedirs('data_lake')\n",
        "\n",
        "# Limita a 10 arquivos e 1000 linhas\n",
        "num_files = 10\n",
        "num_rows_per_file = 1000\n",
        "\n",
        "# Array vazio\n",
        "dfs = []\n",
        "\n",
        "# Loop para criar e salvar os arquivos CSV\n",
        "for i in range(num_files):\n",
        "\n",
        "  # Gerador de informações aleatorias por linha\n",
        "    data = {\n",
        "        'coluna1': np.random.randint(0, 100, num_rows_per_file),\n",
        "        'coluna2': np.random.randn(num_rows_per_file),\n",
        "        'coluna3': np.random.choice(['A', 'B', 'C'], num_rows_per_file)\n",
        "    }\n",
        "\n",
        "    # Cria um DataFrame com os dados\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Define o nome do arquivo e salva em CSV\n",
        "    file_name = f'data_lake/dados{i+1}.csv'\n",
        "    df.to_csv(file_name, index=False)\n",
        "\n",
        "    # Adiciona o nome do arquivo e o DataFrame ao array\n",
        "    dfs.append((file_name, df))\n",
        "\n",
        "print(\"Dados do Data Lake gerados com sucesso!\")\n",
        "\n",
        "# Exibe os registros de cada arquivo gerado\n",
        "for file_name, df in dfs:\n",
        "    print(f\"\\nDados do arquivo: {file_name}\\n\")\n",
        "    print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_W8KHtH5057f",
        "outputId": "ac244513-bc11-4cdf-d3bc-46927e0daffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dados do Data Lake gerados com sucesso!\n",
            "\n",
            "Dados do arquivo: data_lake/dados1.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       43 -0.968874       C\n",
            "1        4  1.872419       A\n",
            "2       98  0.987637       C\n",
            "3       21  1.201710       C\n",
            "4       73  1.618552       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados2.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       64 -0.400384       B\n",
            "1       42  0.351966       B\n",
            "2       66  1.206607       A\n",
            "3        9  1.078723       B\n",
            "4       75  3.082577       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados3.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       76  0.537140       A\n",
            "1        1 -1.706169       A\n",
            "2       69  1.003121       B\n",
            "3       13  0.253347       A\n",
            "4       17  0.003986       C\n",
            "\n",
            "Dados do arquivo: data_lake/dados4.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       23  0.854896       B\n",
            "1       75  0.319192       B\n",
            "2       52  1.002868       A\n",
            "3       41  0.028334       A\n",
            "4       31 -0.243163       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados5.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       45  0.293032       C\n",
            "1       98  0.158415       A\n",
            "2       56  0.824754       A\n",
            "3       44  0.873036       C\n",
            "4       53  0.484621       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados6.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       69  1.235030       C\n",
            "1       83  0.088089       C\n",
            "2        6  1.528733       B\n",
            "3       42 -0.338737       B\n",
            "4       37  0.293657       A\n",
            "\n",
            "Dados do arquivo: data_lake/dados7.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       80 -0.349904       B\n",
            "1       26  1.528187       C\n",
            "2       94 -0.662300       B\n",
            "3       46 -0.046625       B\n",
            "4       91  0.146924       B\n",
            "\n",
            "Dados do arquivo: data_lake/dados8.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       15 -0.883866       C\n",
            "1        8 -0.781427       A\n",
            "2       13  1.000855       B\n",
            "3       90 -1.154123       A\n",
            "4       25 -0.980006       A\n",
            "\n",
            "Dados do arquivo: data_lake/dados9.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       36  0.026173       B\n",
            "1        5 -0.375831       A\n",
            "2       86  1.212247       A\n",
            "3       51 -0.967475       B\n",
            "4       85  0.249318       A\n",
            "\n",
            "Dados do arquivo: data_lake/dados10.csv\n",
            "\n",
            "   coluna1   coluna2 coluna3\n",
            "0       75  1.102641       B\n",
            "1       14  2.157426       C\n",
            "2       26 -0.760738       C\n",
            "3       65  1.061109       A\n",
            "4       32 -0.091515       B\n"
          ]
        }
      ]
    }
  ]
}